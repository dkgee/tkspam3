《机器学习算法原理与编程实践》

本次学习的内容主要包括程序编码、数据结构、数学理论、数据处理、可视化五个方面知识



涉及算法领域
    中文文本分类：主要包括文本分类流程+算法，朴素贝叶斯、KNN最近邻、决策树(ID3\C4.5)；jieba、Scikit-Learning；代码讲解
    文本分类项目（应用领域）：搜索和信息检索（IR）、文本分类、文本聚类、Web挖掘、信息抽取(IE)、
                自然语言处理(NLP)、概念提取。

            扩展思维：数据挖掘（文本数据挖掘（文本分类、文本聚类……））

CH01:【中文文本分类】

中文文本分类流程及技术：
    （1）预处理
    （2）中文分词
    （3）构建词向量空间模型
    （4）权重策略（TF-IDF方法）
    （5）分类器
    （6）评价分类结果
    扩展思维：
        （1）项目中必然涉及业务流程+技术，项目不仅包括核心技术选型，也包括核心的业务流程，这是做好项目的关键。
            换句说法就是，技术是主要骨架、业务流程是经脉、日常工作是血液
        （2）语言分类\检索流程：预处理、分词、构建模型、权重策略、分类\检索、评估

文本分类项目：
    文本预处理主要步骤：
        （1）选择处理的文本范围；
        （2）建立分类文本语料库；
        （3）文本格式转换；
        （4）检测句子边界：标记句子结束。

无论分类、聚类还是信息抽取，其基本工作都是想办法从文本中“发现知识”，而所有的知识都是一种结构化的信息。
一般像这种最后谁也想不明白的问题，最后都交给概率论。

最终完全解决中文分词的算法是基于概率图模型的“条件随机场（CRF）”。这个算法由Lafferty等人于2001年提出。
Jieba分词支持的分词模式包括：默认切分、全切分、搜索引擎切分几种。

open读写模式：r ：只读、r+ : 读写、w ： 新建（会对原有文件进行覆盖）、a ： 追加、b ： 二进制文件

停用词：停用词都是人工输入、非自动化生成的，生成后的停用词会形成一个停用词表。
归一化：我们对整型计数方式进行归一化，归一化可以避免句子长度不一致问题，便于算法计算。
最常用的文本分类法：kNN(最近邻)、朴素贝叶斯、支持向量机